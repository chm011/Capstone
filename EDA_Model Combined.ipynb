{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59c1bd3-16bf-402c-babb-e62b9f9a7589",
   "metadata": {},
   "source": [
    "# Part 1: Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f3ec0-e107-4858-b6c3-8da3d867944d",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e391df1-f9c0-4486-8c32-3a88a5308ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392e13d-16a4-4714-8afe-24cf5641c947",
   "metadata": {},
   "source": [
    "### Loading and Compiling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1122fc2-79fa-49d3-9729-e0d24bec89b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing data\n",
    "#df = pd.read_csv('Combined_LCA_Disclosure_Data_FY2020_to_FY2024.csv', low_memory=False)\n",
    "df2020 = pd.read_csv('Combined_LCA_Disclosure_Data_FY2020.csv', low_memory=False)\n",
    "df2021 = pd.read_csv('Combined_LCA_Disclosure_Data_FY2021.csv', low_memory=False)\n",
    "df2022 = pd.read_csv('Combined_LCA_Disclosure_Data_FY2022.csv', low_memory=False)\n",
    "df2023 = pd.read_csv('Combined_LCA_Disclosure_Data_FY2023.csv', low_memory=False)\n",
    "df2024 = pd.read_csv('Combined_LCA_Disclosure_Data_FY2024.csv', low_memory=False)\n",
    "all_data = [df2020, df2021,df2022,df2023,df2024]\n",
    "\n",
    "df = pd.concat(all_data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab03d2d-98d7-497d-a795-c9a888b491b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete previous dataframes to free memory\n",
    "del df2020, df2021, df2022, df2023, df2024, all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4aeee-2a75-4f17-ba3d-eb9bfea20926",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89655696-ae65-480d-8406-db7022975b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55b1e1-7306-472f-aaaa-e8c0570dc42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5b047-33a7-4c96-bbae-326316587a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing value\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885f87d-4136-45e9-929a-91a9539d2885",
   "metadata": {},
   "source": [
    "The dataset contains several missing values, which will be addressed appropriately after selecting the features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2ce14-7b45-499a-92f8-b331143791cb",
   "metadata": {},
   "source": [
    "# Part 2: Exploratory Data Analysis & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1b957-3f7d-4952-947e-c4de779a8120",
   "metadata": {},
   "source": [
    "### Case Status Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f56bcc-ec7a-4d81-b985-2a0a3b9cc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of case statuses\n",
    "case_status_counts = df['CASE_STATUS'].value_counts()\n",
    "\n",
    "# Case status distribution using pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "case_status_counts.plot(kind='pie', startangle=90, cmap='Set3',autopct='%1.1f%%', textprops={'rotation':45},legend=True)\n",
    "plt.title('Case Status Distribution', fontsize=16)\n",
    "plt.ylabel('')  # Remove y-label for better appearance\n",
    "plt.legend(loc='right',bbox_to_anchor=(1.4, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66466e-6c40-46da-b1e7-e71310612c0a",
   "metadata": {},
   "source": [
    "### Total Number of Applications Over the Years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af66b62-551e-4cac-9ec9-9a264463a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of applications over the years (2020-2024)\n",
    "df['YEAR'] = pd.to_datetime(df['DECISION_DATE']).dt.year  # Extract year from decision date\n",
    "yearly_applications = df['YEAR'].value_counts().sort_index()\n",
    "print(yearly_applications) #Checking Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40354c-3f78-4a72-bfa1-ff67187a4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(yearly_applications.index, yearly_applications.values, color='skyblue')\n",
    "plt.title('Total H1B Applications by Year', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Number of Applications', fontsize=12)\n",
    "plt.xticks(yearly_applications.index)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a0fcf-0878-48a2-a90d-6b440b724ca6",
   "metadata": {},
   "source": [
    "### Number of H1B Applicants by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1832a-7e74-4e39-8ad5-378bbf4d2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataFrame\n",
    "state_counts = df['EMPLOYER_STATE'].value_counts().reset_index()\n",
    "state_counts.columns = ['State', 'Applicants']\n",
    "\n",
    "# Use Plotly Express to create a choropleth map\n",
    "fig = px.choropleth(\n",
    "    state_counts,\n",
    "    locations='State',          # Column with state abbreviations\n",
    "    locationmode='USA-states',  # Specify USA states\n",
    "    color='Applicants',         # Color by the number of applicants\n",
    "    color_continuous_scale='Viridis',  # Color scale\n",
    "    scope='usa',                # Focus on the USA\n",
    "    title='Number of H1B Applicants by State',\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Display the map\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7927b-d447-472e-aae6-ea6b00ef233f",
   "metadata": {},
   "source": [
    "### Top 10 Occupations in H1B Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7602c9-3a5c-43f4-8af1-075a8c76082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top occupations in the dataset\n",
    "top_occupations = df['SOC_TITLE'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_occupations.plot(kind='barh', color='lightgreen', edgecolor='black')\n",
    "plt.title('Top 10 Occupations in H1B Applications', fontsize=16)\n",
    "plt.xlabel('Number of Applications', fontsize=12)\n",
    "plt.ylabel('Occupation', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978521b-689a-4811-98f3-688de36abfab",
   "metadata": {},
   "source": [
    "### Salary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04865e-a429-4efc-b885-4aa4f1346b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean and convert salaries to numeric, handling outliers\n",
    "unique_units = df['PW_UNIT_OF_PAY'].unique()\n",
    "print(unique_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e22fc7-83ec-49aa-9169-2ab12dcf81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert salaries to 'Year'\n",
    "df['PREVAILING_WAGE'] = pd.to_numeric(df['PREVAILING_WAGE'], errors='coerce')\n",
    "df = df[df['PREVAILING_WAGE'] > 0]  # Filter out non-positive values\n",
    "\n",
    "conversion_factors = {\n",
    "    'Year': 1,            # No Normalization\n",
    "    'Month': 12,          # 12 months in a year\n",
    "    'Bi-Weekly': 26,      # 26 bi-weekly periods in a year\n",
    "    'Week': 52,           # 52 weeks in a year\n",
    "    'Hour': 2080          # 52 weeks in a year x 40 hrs a week\n",
    "}\n",
    "\n",
    "df['ANNUAL_WAGE'] = df.apply(\n",
    "    lambda row: row['PREVAILING_WAGE'] * conversion_factors.get(row['PW_UNIT_OF_PAY'], 1),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd09cb7-abbe-4c03-a983-4c196cda37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of Annual Wage\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['ANNUAL_WAGE'], bins=50, kde=True, color='blue')\n",
    "plt.title('Distribution of Annual Wage', fontsize=16)\n",
    "plt.xlabel('Annual Wage', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b2d3c-8346-4de2-8091-4cb6a4e17e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers at the 99th percentile\n",
    "wage_cap = df['ANNUAL_WAGE'].quantile(0.99)\n",
    "filtered_df = df[df['ANNUAL_WAGE'] <= wage_cap]\n",
    "\n",
    "# Plot the distribution of Annual Wage with outliers capped\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(filtered_df['ANNUAL_WAGE'], bins=50, kde=True, color='blue')\n",
    "plt.title('Distribution of Annual Wage (Capped at 99th Percentile)', fontsize=16)\n",
    "plt.xlabel('Annual Wage', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214857be-dfec-44ca-9b8c-a6bdb81b2f26",
   "metadata": {},
   "source": [
    "### Top 10 Occupations by Average Annual Wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05a996-8f14-46cd-a1d5-0f70ce9e19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze average salaries by occupation\n",
    "avg_salaries = df.groupby('SOC_TITLE')['ANNUAL_WAGE'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "avg_salaries.plot(kind='barh', color='purple', edgecolor='black')\n",
    "plt.title('Top 10 Occupations by Average Annual Wage', fontsize=16)\n",
    "plt.xlabel('Average Annual Wage', fontsize=12)\n",
    "plt.ylabel('Occupation', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a0851-94b5-453d-bbd4-c12f61789b74",
   "metadata": {},
   "source": [
    "### Top 10 Employers for H1B Applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a3308-95c1-455f-b984-bae6e06dfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding for EMPLOYER_NAME\n",
    "\n",
    "frequency_encoding = df['EMPLOYER_NAME'].value_counts(normalize=True)  # Compute frequency\n",
    "df['EMPLOYER_NAME_FREQUENCY'] = df['EMPLOYER_NAME'].map(frequency_encoding)  # Map to DataFrame\n",
    "\n",
    "# Get top 10 high-frequency companies\n",
    "top_10_employers = frequency_encoding.head(10)\n",
    "\n",
    "# Display the top 10\n",
    "print(\"Top 10 Employers by Frequency:\")\n",
    "print(top_10_employers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5667e15e-992b-4fba-b605-9204aa3d99d0",
   "metadata": {},
   "source": [
    "### Finding Correlation Between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a9958-901f-4bf0-8a3a-1bb6fb5ab17b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get the processing time from subtracting decision date and start date and case status is certified\n",
    "#processing the time into usable format\n",
    "\n",
    "df['BEGIN_DATE'] = pd.to_datetime(df['BEGIN_DATE'])\n",
    "df['DECISION_DATE'] = pd.to_datetime(df['DECISION_DATE'])\n",
    "df['RECEIVED_DATE'] = pd.to_datetime(df['RECEIVED_DATE'])\n",
    "\n",
    "\n",
    "print(df.BEGIN_DATE.value_counts())\n",
    "print(df.DECISION_DATE.value_counts())\n",
    "df['Decision_Duration'] = df['BEGIN_DATE'] - df['DECISION_DATE']\n",
    "\n",
    "df.Decision_Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9a586-513a-4854-9000-9bb44161921c",
   "metadata": {},
   "source": [
    "##### Filtering Dataframe for Variables Possibly Related to Case Staus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09dd8c3-97a6-4c14-b748-ab71f58446cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering current df\n",
    "#df1 = df.copy()\n",
    "df1 = df[['CASE_STATUS','Decision_Duration','RECEIVED_DATE','SOC_TITLE','FULL_TIME_POSITION','EMPLOYER_NAME','EMPLOYER_CITY','EMPLOYER_STATE','AGENT_REPRESENTING_EMPLOYER','TOTAL_WORKER_POSITIONS','WORKSITE_CITY','WORKSITE_STATE','WORKSITE_WORKERS','WORKSITE_POSTAL_CODE','AGENT_ATTORNEY_CITY','AGENT_ATTORNEY_STATE','ANNUAL_WAGE','H_1B_DEPENDENT','SUPPORT_H1B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8cbe0-1be9-4d6e-82c0-527f656447ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing features\n",
    "#:'Decision_Duration','TOTAL_WORKER_POSITIONS','ANNUAL_WAGE'\n",
    "Categorical:'CASE_STATUS','RECEIVED_DATE','SOC_TITLE','FULL_TIME_POSITION','EMPLOYER_NAME','EMPLOYER_CITY','EMPLOYER_STATE','AGENT_REPRESENTING_EMPLOYER','WORKSITE_CITY','WORKSITE_STATE','WORKSITE_WORKERS','WORKSITE_POSTAL_CODE','AGENT_ATTORNEY_CITY','AGENT_ATTORNEY_STATE','H_1B_DEPENDENT','SUPPORT_H1B']\n",
    "'''\n",
    "\n",
    "cat_columns = ['CASE_STATUS','RECEIVED_DATE','SOC_TITLE','FULL_TIME_POSITION','EMPLOYER_NAME','EMPLOYER_CITY','EMPLOYER_STATE','AGENT_REPRESENTING_EMPLOYER','WORKSITE_CITY','WORKSITE_STATE','WORKSITE_WORKERS','WORKSITE_POSTAL_CODE','AGENT_ATTORNEY_CITY','AGENT_ATTORNEY_STATE','H_1B_DEPENDENT','SUPPORT_H1B']\n",
    "for col in cat_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df1[col] = label_encoder.fit_transform(df1[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfacced-539c-44e2-9224-d20c0018d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4aefa-635f-4e3a-903d-2759e3665753",
   "metadata": {},
   "source": [
    "#### Finding Correlation Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0a6fc-217c-42d3-8448-68b76cd7d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Spearman correlation can help detect non-linear, categorical, and ordinal data. Good at ranked variables. So maybe it's better in this case when compared to pearson.\n",
    "'''\n",
    "#spearman correlation\n",
    "corr = df1.corr(method='spearman')\n",
    "corr_matrix = corr['CASE_STATUS']\n",
    "print(corr_matrix.sort_values(ascending=False))\n",
    "\n",
    "#pearson correlation\n",
    "pearson_corr = df1.corr()\n",
    "pearson_corr_matrix = pearson_corr['CASE_STATUS']\n",
    "print(pearson_corr_matrix.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6a6cd-f6f1-4754-8778-bbbce5b67154",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = corr['CASE_STATUS'].drop('CASE_STATUS').sort_values(ascending=False)\n",
    "target_pearcorr = pearson_corr['CASE_STATUS'].drop('CASE_STATUS').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d8e9c-a831-4e80-8568-f418119cad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "# Plot Pearson correlation\n",
    "sns.barplot(x=target_pearcorr.values, y=target_pearcorr.index, palette=\"coolwarm\", hue=target_pearcorr.index , ax=axes[0], legend=False)\n",
    "axes[0].set_title(\"Feature Correlation with Case Status (Pearson)\")\n",
    "axes[0].set_xlabel(\"Correlation with Case Status\")\n",
    "axes[0].set_ylabel(\"Features\")\n",
    "\n",
    "# Plot Spearman correlation\n",
    "sns.barplot(x=target_corr.values, y=target_corr.index, palette=\"coolwarm\", hue=target_corr.index, ax=axes[1], legend=False)\n",
    "axes[1].set_title(\"Feature Correlation with Case Status (Spearman)\")\n",
    "axes[1].set_xlabel(\"Correlation with Case Status\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5c6fe-bb68-4e4a-ac32-b0ad224e017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spearman correlation matrix\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.show()\n",
    "\n",
    "target_corr = corr['CASE_STATUS'].drop('CASE_STATUS').sort_values(ascending=False)\n",
    "\n",
    "'''\n",
    "# Plot as a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=target_corr.values, y=target_corr.index, palette=\"coolwarm\")\n",
    "plt.xlabel(\"Correlation with Case Status\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Correlation with Cade Status - Spearman\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5b252-1972-4c29-9737-93e662d8b9fb",
   "metadata": {},
   "source": [
    "#### Mutual Information Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569afde8-95f8-4c0a-b998-898403037bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Decision_Duration'] = df1['Decision_Duration'].dt.days\n",
    "X = df1.drop(columns=['CASE_STATUS'])\n",
    "y = df1['CASE_STATUS'] \n",
    "\n",
    "mi_scores = mutual_info_classif(X, y, discrete_features=False)\n",
    "mi_scores_df = pd.DataFrame({'Feature': X.columns, 'Mutual Information Score': mi_scores})\n",
    "mi_scores_df = mi_scores_df.sort_values(by=\"Mutual Information Score\", ascending=False)\n",
    "print(mi_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a754c1c-da0a-4f48-a3db-dc7f7e49e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mutual information scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=mi_scores_df['Mutual Information Score'], y=mi_scores_df['Feature'], palette=\"viridis\")\n",
    "plt.xlabel(\"Mutual Information Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance Based on Mutual Information\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e372e-a7e5-432a-a846-cf2d37676d34",
   "metadata": {},
   "source": [
    "# Part 3: Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504963aa-0aac-4cd5-b82b-534cfe80c801",
   "metadata": {},
   "source": [
    "## Filtering Out DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02e02b-4a73-4574-8173-a34cbff7b2d2",
   "metadata": {},
   "source": [
    "### 1. Selecting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e66a4-0744-46e1-ac74-96f54b50c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting features based on correlation coefficients from last section\n",
    "selectdf = df.loc[:, \n",
    "    ['CASE_STATUS',\n",
    "     'SOC_TITLE',\n",
    "     'ANNUAL_WAGE',\n",
    "     'SUPPORT_H1B',\n",
    "     'H_1B_DEPENDENT',\n",
    "     'EMPLOYER_NAME',\n",
    "     'EMPLOYER_STATE',\n",
    "     'EMPLOYER_CITY',\n",
    "     'AGENT_REPRESENTING_EMPLOYER',\n",
    "     'AGENT_ATTORNEY_STATE',\n",
    "     'AGENT_ATTORNEY_CITY',\n",
    "     'FULL_TIME_POSITION',\n",
    "     'WORKSITE_STATE',\n",
    "     'WORKSITE_CITY',\n",
    "     'WORKSITE_POSTAL_CODE',\n",
    "     'WORKSITE_WORKERS',\n",
    "     'TOTAL_WORKER_POSITIONS',\n",
    "     'RECEIVED_DATE',\n",
    "     'Decision_Duration'\n",
    "    ]]\n",
    "selectdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bec3f-0a66-489b-a115-646986597b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectdf[\"WORKSITE_WORKERS\"] = selectdf[\"WORKSITE_WORKERS\"].fillna(0).astype(int)\n",
    "selectdf.WORKSITE_WORKERS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40973d6a-5ed6-4392-af9d-d7d441377fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e3587-0449-4c18-86a6-d66767ad6f5e",
   "metadata": {},
   "source": [
    "### 2. Filtering \"CASE_STATUS\" for Certified and Denied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c23fee-9a19-4bba-ba2c-3c10c939b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see count before\n",
    "print(selectdf.CASE_STATUS.value_counts())\n",
    "\n",
    "#filter out case status into certifief and withdrawn only\n",
    "#save into selectdf_filtered\n",
    "selectdf_filtered = selectdf[selectdf['CASE_STATUS'].isin(['Certified', 'Denied'])]\n",
    "print(selectdf_filtered.CASE_STATUS.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6670fb4-34f9-48d1-9759-d976df38d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#free up memory\n",
    "del df, selectdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a4053-95ac-41bc-8db3-7abb0c8ba28c",
   "metadata": {},
   "source": [
    "### 3. Transforming DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98acd18-10aa-4482-831c-b8c7faeb0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing features\n",
    "#:'Decision_Duration','TOTAL_WORKER_POSITIONS','ANNUAL_WAGE'\n",
    "Categorical:\n",
    "    'CASE_STATUS',\n",
    "    'SOC_TITLE',\n",
    "    'SUPPORT_H1B',\n",
    "    'H_1B_DEPENDENT',\n",
    "    'EMPLOYER_NAME',\n",
    "    'EMPLOYER_STATE',\n",
    "    'EMPLOYER_CITY',\n",
    "    'AGENT_REPRESENTING_EMPLOYER',\n",
    "    'AGENT_ATTORNEY_STATE',\n",
    "    'AGENT_ATTORNEY_CITY',\n",
    "    'FULL_TIME_POSITION',\n",
    "    'WORKSITE_STATE',\n",
    "    'WORKSITE_CITY',\n",
    "    'WORKSITE_POSTAL_CODE',\n",
    "    'RECEIVED_DATE']]\n",
    "'''\n",
    "selectdf_filtered = selectdf_filtered.copy()\n",
    "\n",
    "#Label Encoding for categorical features\n",
    "cat_columns = [\n",
    "    'CASE_STATUS',\n",
    "    'SOC_TITLE',\n",
    "    'SUPPORT_H1B',\n",
    "    'H_1B_DEPENDENT',\n",
    "    'EMPLOYER_NAME',\n",
    "    'EMPLOYER_STATE',\n",
    "    'EMPLOYER_CITY',\n",
    "    'AGENT_REPRESENTING_EMPLOYER',\n",
    "    'AGENT_ATTORNEY_STATE',\n",
    "    'AGENT_ATTORNEY_CITY',\n",
    "    'FULL_TIME_POSITION',\n",
    "    'WORKSITE_STATE',\n",
    "    'WORKSITE_CITY',\n",
    "    'WORKSITE_POSTAL_CODE',\n",
    "    'RECEIVED_DATE'\n",
    "    ]\n",
    "\n",
    "#prevent categories from mismatching\n",
    "label_encoder= {}\n",
    "for col in cat_columns:\n",
    "    label_encoder[col] = LabelEncoder()\n",
    "    selectdf_filtered[col] = label_encoder[col].fit_transform(selectdf_filtered[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2927822-93af-438d-b07f-548dcb4157fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selectdf_filtered.CASE_STATUS.value_counts())\n",
    "print(selectdf_filtered.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75002ee-3725-4b08-8846-6ecbe4a3e39e",
   "metadata": {},
   "source": [
    "### 4. Defining target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3dde4-db4d-42a3-9635-a06dbba68d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target = 'CASE_STATUS'\n",
    "features = ['SOC_TITLE', 'ANNUAL_WAGE', 'SUPPORT_H1B', 'H_1B_DEPENDENT', 'EMPLOYER_NAME', 'EMPLOYER_STATE', \n",
    "            'EMPLOYER_CITY', 'AGENT_REPRESENTING_EMPLOYER', 'AGENT_ATTORNEY_STATE', 'AGENT_ATTORNEY_CITY',\n",
    "            'FULL_TIME_POSITION', 'WORKSITE_STATE', 'WORKSITE_CITY', 'WORKSITE_POSTAL_CODE',\n",
    "            'WORKSITE_WORKERS', 'TOTAL_WORKER_POSITIONS', 'RECEIVED_DATE', 'Decision_Duration']\n",
    "\n",
    "X = selectdf_filtered[features]\n",
    "y = selectdf_filtered[target]\n",
    "\n",
    "#Ensuring y is integer\n",
    "y = y.astype(int)\n",
    "\n",
    "#Test,train,split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259d840-44ca-4ca1-9cd3-c6907f236be0",
   "metadata": {},
   "source": [
    "# Part 4: Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc631a94-66a1-457b-a21d-7516dbf8d248",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423740e-610e-499a-bb16-e50f5212b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling features for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9f4c8-ad40-49d5-b84d-345dfe199830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with imbalance data\n",
    "lg_imbalanced = LogisticRegression(max_iter=1000, solver='newton-cg')\n",
    "lg_imbalanced.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "lg_imbalanced_y_pred = lg_imbalanced.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy of Logistic Regression(imbalanced):\",accuracy_score(y_test, lg_imbalanced_y_pred))\n",
    "print(classification_report(y_test, lg_imbalanced_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8db20-0a7a-4ae7-96ce-325758d85228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up model with balanced dataset\n",
    "\n",
    "#Balance the dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#scale again to ensure it can converge\n",
    "X_train_smote_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47f950-166a-45dd-b883-fa4ea1ca3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up model with balanced\n",
    "lg = LogisticRegression(max_iter=1000, solver='newton-cg')\n",
    "lg.fit(X_train_smote_scaled, y_train_smote)\n",
    "\n",
    "# Predictions\n",
    "lg_y_pred = lg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "lg_accuracy = accuracy_score(y_test, lg_y_pred)\n",
    "lg_report = classification_report(y_test, lg_y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy of Logistic Regression(balanced):\", lg_accuracy)\n",
    "print(lg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867bcea-ef60-4613-b23c-c2458fe03af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute confusion matrix and plot\n",
    "def plot_confusion_matrix(y_true, y_pred, title, ax):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    sns.heatmap(cm_percentage, annot=True, fmt='.2f', cmap='Blues', ax=ax, xticklabels=['Certified', 'Denied'], yticklabels=['Certified', 'Denied'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_confusion_matrix(y_test, lg_imbalanced_y_pred, 'LG Confusion Matrix - Imbalanced Model (%)', axes[0])\n",
    "plot_confusion_matrix(y_test, lg_y_pred, 'LG Confusion Matrix - Balanced Model (%)', axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3257b1-795b-43a5-b89e-68bfcfa9e075",
   "metadata": {},
   "source": [
    "### 2. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb627277-c2fd-426a-94f6-09edc1ad732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up nn\n",
    "def create_nn():\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d927b6-f17c-462e-9530-b4aee112aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with imbalanced dataset\n",
    "nn_imbalanced = create_nn()\n",
    "nn_imbalanced.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the imbalanced model\n",
    "nn_y_pred_imbalanced = (nn_imbalanced.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(\"Imbalanced Neural Network:\")\n",
    "print(\"Accuracy of imbalanced NN:\", accuracy_score(y_test, nn_y_pred_imbalanced))\n",
    "print(classification_report(y_test, nn_y_pred_imbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acee454-ce1f-45e7-9a2a-ca6a98e72794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up model with balanced dataset\n",
    "\n",
    "#Balance the dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#scaling \n",
    "X_train_smote_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f912c74-2c78-4caa-9fe8-7e8180b5c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train balanced dataset\n",
    "nn_balanced = create_nn()\n",
    "nn_balanced.fit(X_train_smote_scaled, y_train_smote, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the balanced model\n",
    "nn_y_pred_balanced = (nn_balanced.predict(X_test_scaled) > 0.5).astype(int)\n",
    "print(\"Balanced Neural Network with SMOTE:\")\n",
    "print(\"Accuracy of balanced NN:\", accuracy_score(y_test, nn_y_pred_balanced))\n",
    "print(classification_report(y_test, nn_y_pred_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1998b-88dd-4a93-9df5-bde15c0613ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute and plot confusion matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_confusion_matrix(y_test, nn_y_pred_imbalanced, 'NN Confusion Matrix - Imbalanced Model (%)', axes[0])\n",
    "plot_confusion_matrix(y_test, nn_y_pred_balanced, 'NN Confusion Matrix - Balanced Model (%)', axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb6575-d77f-4346-92ea-6d3f5ab88b05",
   "metadata": {},
   "source": [
    "### 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbac0c-8730-48da-896c-150bcf226342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train XGBoost model\n",
    "xgb_model_imbalanced = XGBClassifier(eval_metric='logloss')\n",
    "xgb_model_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "yXGB_pred_imbalanced = xgb_model_imbalanced.predict(X_test)\n",
    "print(\"XGBoost_Imbalanced_Accuracy:\", accuracy_score(y_test, yXGB_pred_imbalanced))\n",
    "print(classification_report(y_test, yXGB_pred_imbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5561d4e-4614-40b2-83bc-0896a17273d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply oversampling to balance the dataset\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train XGBoost with balanced data\n",
    "xgb_model_balanced = XGBClassifier(eval_metric='logloss')\n",
    "xgb_model_balanced.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predictions and evaluation\n",
    "yXGB_pred_balanced = xgb_model_balanced.predict(X_test)\n",
    "print(\"XGBoost_Balanced_Accuracy_:\", accuracy_score(y_test, yXGB_pred_balanced))\n",
    "print(classification_report(y_test, yXGB_pred_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b21796-a5e1-40da-ab20-a12f64e3f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_confusion_matrix(y_test, yXGB_pred_imbalanced, 'XGB Confusion Matrix - Imbalanced Model (%)', axes[0])\n",
    "plot_confusion_matrix(y_test, yXGB_pred_balanced, 'XGB Confusion Matrix - Balanced Model (%)', axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7bddbd-aff6-4c3a-a70f-fa0a38304d89",
   "metadata": {},
   "source": [
    "### 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5b52b-e1d5-428e-81b4-4fc4131d1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Random Forest model\n",
    "rf_model_imbalanced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "yRF_pred_imbalanced = rf_model_imbalanced.predict(X_test)\n",
    "print(\"Accuracy_Random Forest:\", accuracy_score(y_test, yRF_pred_imbalanced))\n",
    "print(classification_report(y_test, yRF_pred_imbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097ada4-307d-4e8b-b746-88cf96834f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Random Forest model with balanced train dataset\n",
    "rf_model_balanced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_balanced.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predictions and evaluation\n",
    "yRF_pred_balanced = rf_model_balanced.predict(X_test)\n",
    "print(\"Accuracy_Random Forest:\", accuracy_score(y_test, yRF_pred_balanced))\n",
    "print(classification_report(y_test, yRF_pred_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8ffe0-12fa-43ac-94ca-907a81106454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization \n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_confusion_matrix(y_test, yRF_pred_imbalanced, 'RF Confusion Matrix - Imbalanced Model (%)', axes[0])\n",
    "plot_confusion_matrix(y_test, yRF_pred_balanced, 'RF Confusion Matrix - Balanced Model (%)', axes[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
